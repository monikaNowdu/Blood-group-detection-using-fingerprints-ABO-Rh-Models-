{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0IXQVUDW0zI-",
      "metadata": {
        "id": "0IXQVUDW0zI-"
      },
      "source": [
        "# üî¨ Blood Group Detection from Fingerprint using Deep Learning\n",
        "Organized Google Colab Notebook (Training Once, Then Just Load)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0A0AYiH10zJB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0A0AYiH10zJB",
        "outputId": "f06684fb-52ae-4c07-adf8-6327dac50502"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Part 1: Setup & Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_D61XM250zJE",
      "metadata": {
        "id": "_D61XM250zJE"
      },
      "outputs": [],
      "source": [
        "#  Part 2: Paths & Constants\n",
        "img_width, img_height = 224, 224\n",
        "batch_size = 32\n",
        "\n",
        "data_dir = \"/content/drive/My Drive/dataset_blood_group\"\n",
        "model_path = \"/content/drive/My Drive/blood_group_detector.h5\"\n",
        "encoder_path = \"/content/drive/My Drive/label_encoder.pkl\"\n",
        "checkpoint_path = \"/content/drive/My Drive/checkpoints/cp-{epoch:02d}.weights.h5\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tnKrlSAu0zJF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnKrlSAu0zJF",
        "outputId": "cde7f630-ed7c-4b5d-c0af-36dccbcc3a1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Loaded saved model and encoder.\n"
          ]
        }
      ],
      "source": [
        "#  Part 3: Load or Train Model\n",
        "if os.path.exists(model_path):\n",
        "    model = load_model(model_path)\n",
        "    with open(encoder_path, 'rb') as f:\n",
        "        encoder = pickle.load(f)\n",
        "    print(\" Loaded saved model and encoder.\")\n",
        "else:\n",
        "    print(\" Training model...\")\n",
        "\n",
        "    datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "    train_generator = datagen.flow_from_directory(\n",
        "        data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        subset='training'\n",
        "    )\n",
        "\n",
        "    val_generator = datagen.flow_from_directory(\n",
        "        data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        subset='validation'\n",
        "    )\n",
        "\n",
        "    classes = train_generator.class_indices.keys()\n",
        "    encoder = LabelEncoder()\n",
        "    encoder.fit(list(classes))\n",
        "    with open(encoder_path, 'wb') as f:\n",
        "        pickle.dump(encoder, f)\n",
        "\n",
        "    model = Sequential([\n",
        "        tf.keras.Input(shape=(img_width, img_height, 3)),\n",
        "        Conv2D(32, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(len(classes), activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=checkpoint_path,\n",
        "        save_weights_only=True,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        validation_data=val_generator,\n",
        "        epochs=10,\n",
        "        callbacks=[checkpoint_cb]\n",
        "    )\n",
        "\n",
        "    model.save(model_path)\n",
        "    print(\" Model trained and saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lZIcGFTo0zJG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZIcGFTo0zJG",
        "collapsed": true,
        "outputId": "f9382135-cc3f-4d9b-9feb-5089dae9ab4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
            "Predicted Blood Group: AB-\n"
          ]
        }
      ],
      "source": [
        "#  Part 4: Predict from Image\n",
        "def predict_blood_group(image_path):\n",
        "    img = load_img(image_path, target_size=(img_width, img_height))\n",
        "    img = img_to_array(img) / 255.0\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    prediction = model.predict(img)\n",
        "    predicted_class = np.argmax(prediction)\n",
        "    blood_group = encoder.inverse_transform([predicted_class])[0]\n",
        "    return blood_group\n",
        "\n",
        "# Example\n",
        "sample_path = \"cluster_5_54.BMP\"  # Change this to your image\n",
        "print(\"Predicted Blood Group:\", predict_blood_group(sample_path))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}